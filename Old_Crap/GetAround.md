## ğŸ§­ **Plan Global du Projet Getaround**

### ğŸ¯ Objectifs principaux :

1. **Analyse des retards** (Data analysis & dashboard)
2. **ModÃ¨le de prÃ©diction de prix** (Machine Learning + API)
3. **Mise en ligne :** un tableau de bord + une API avec documentation

---

## ğŸ› ï¸ Outils Ã  utiliser

| Partie du projet     | Outils recommandÃ©s                                                              |
| -------------------- | ------------------------------------------------------------------------------- |
| Analyse de donnÃ©es   | `pandas`, `matplotlib`, `seaborn`, `numpy`                                      |
| Dashboard Web        | `Streamlit` (simple et parfait pour dÃ©butants)                                  |
| Machine Learning     | `scikit-learn`, `pandas`                                                        |
| API & Documentation  | `FastAPI` (simple), `Uvicorn` (serveur), `Swagger` (auto-documentation)         |
| Mise en ligne        | `Hugging Face Spaces` pour Streamlit + FastAPI ou `Render`, `Railway`, `Vercel` |
| Versioning & partage | `Git`, `GitHub`                                                                 |

---

## ğŸ“ Organisation de ton projet

```
getaround-project/
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ getaround_delay_analysis.csv
â”‚   â””â”€â”€ getaround_pricing_optimization.csv
â”‚
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ analyse_retards.ipynb
â”‚
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ dashboard.py         # ton app Streamlit
â”‚   â”œâ”€â”€ api.py               # ton API FastAPI
â”‚   â””â”€â”€ model.pkl            # modÃ¨le de ML entraÃ®nÃ©
â”‚
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ README.md
â””â”€â”€ .gitignore
```

---

## âœ… Ã‰tape 1 : Analyse des retards & dashboard (Data Analysis)

### ğŸ“Œ Objectif : rÃ©pondre aux questions du chef produit

#### 1.1 Charger et comprendre les donnÃ©es

* Fichier : `getaround_delay_analysis.csv`
* Utilise un notebook Jupyter (`notebooks/analyse_retards.ipynb`)

```python
import pandas as pd

df = pd.read_csv('data/getaround_delay_analysis.csv')
df.head()
df.info()
df.describe()
```

#### 1.2 Analyser les cas de retard

* CrÃ©e une colonne `delay_in_minutes = actual_end_time - scheduled_end_time`
* Identifie les retards critiques (si une autre location commence juste aprÃ¨s)

#### 1.3 RÃ©pondre aux questions :

* Combien de locations ont Ã©tÃ© affectÃ©es par des retards ?
* Quelle est la proportion de voitures connectÃ©es affectÃ©es ?
* Quel pourcentage du chiffre dâ€™affaires cela reprÃ©sente ?

Utilise des visualisations :

```python
import seaborn as sns
import matplotlib.pyplot as plt

sns.histplot(df['delay_in_minutes'])
```

#### 1.4 CrÃ©e ton dashboard Streamlit (`dashboard.py`)

```python
import streamlit as st
import pandas as pd

st.title("Analyse des retards - Getaround")
df = pd.read_csv("data/getaround_delay_analysis.csv")
st.dataframe(df.head())
# Affiche des graphes, KPIs, sliders pour seuils, etc.
```

#### 1.5 HÃ©berge ton app :

* CrÃ©e un compte Hugging Face
* HÃ©berge avec un dÃ©pÃ´t Streamlit : [https://huggingface.co/docs/hub/spaces](https://huggingface.co/docs/hub/spaces)

---

## âœ… Ã‰tape 2 : ModÃ¨le de prÃ©diction de prix (Machine Learning)

### 2.1 Charger et comprendre les donnÃ©es

* Fichier : `getaround_pricing_optimization.csv`

### 2.2 PrÃ©traitement

* Supprimer les colonnes inutiles
* GÃ©rer les valeurs manquantes
* Normaliser si besoin

### 2.3 EntraÃ®ner un modÃ¨le simple

```python
from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error
import joblib

X = df.drop("rental_price_per_day", axis=1)
y = df["rental_price_per_day"]

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)
model = RandomForestRegressor()
model.fit(X_train, y_train)

joblib.dump(model, "app/model.pkl")
```

---

## âœ… Ã‰tape 3 : API avec /predict et /docs (FastAPI)

### 3.1 CrÃ©e lâ€™API (`api.py`)

```python
from fastapi import FastAPI
from pydantic import BaseModel
import joblib
import numpy as np

app = FastAPI()
model = joblib.load("model.pkl")

class InputData(BaseModel):
    input: list

@app.post("/predict")
def predict(data: InputData):
    inputs = np.array(data.input)
    preds = model.predict(inputs).tolist()
    return {"prediction": preds}

@app.get("/docs")
def documentation():
    return {
        "title": "API de prÃ©diction des prix",
        "endpoints": {
            "/predict": {
                "method": "POST",
                "input": [[...features]],
                "output": "[prix estimÃ©]"
            }
        }
    }
```

### 3.2 Teste localement

```bash
uvicorn app.api:app --reload
```

### 3.3 HÃ©berge ton API (Hugging Face Spaces + `FastAPI`)

* Regarde cet exemple : [https://huggingface.co/spaces/yuntian-deng/fastapi-template](https://huggingface.co/spaces/yuntian-deng/fastapi-template)

---

## âœ… Ã‰tape 4 : README + GitHub

CrÃ©e un fichier `README.md` :

````md
# Getaround - Projet Data Science

## ğŸ“Š Objectifs
- Analyser les retards de retour
- Construire un modÃ¨le de prÃ©diction des prix
- Fournir une API en ligne et un tableau de bord

## ğŸ”— Liens
- Dashboard Streamlit : [URL Hugging Face]
- API FastAPI : [URL API Hugging Face]
- Documentation API : [URL]/docs

## ğŸš€ Installation
```bash
git clone ...
pip install -r requirements.txt
````

```

---

## âœ… Ã‰tape 5 : Bonus

Tu peux ajouter :
- Un systÃ¨me de logs dans lâ€™API
- Un formulaire interactif dans Streamlit
- Une fonctionnalitÃ© de tÃ©lÃ©chargement CSV de rÃ©sultats

---

## â±ï¸ Temps estimÃ©

| Ã‰tape                            | DurÃ©e estimÃ©e       |
|----------------------------------|---------------------|
| Analyse des donnÃ©es              | 3-4h                |
| Construction du dashboard        | 2h                  |
| Machine learning + test          | 3h                  |
| CrÃ©ation de lâ€™API FastAPI        | 2h                  |
| Mise en ligne (Hugging Face)     | 1h                  |
| README et finalisation           | 1h                  |
| **Total estimÃ©**                 | **12-15 heures**    |

---

## ğŸ§¡ Tu peux le faire !

Câ€™est un **trÃ¨s bon projet pour apprendre** Ã  faire une analyse complÃ¨te de donnÃ©es **de A Ã  Z**, avec de la mise en production.

Si tu veux, je peux tâ€™aider Ã  chaque Ã©tape : analyser ton CSV, coder le modÃ¨le, dÃ©ployer lâ€™API, etc. Tu veux quâ€™on commence par lâ€™analyse de donnÃ©es ensemble ? ğŸ˜Š
```
